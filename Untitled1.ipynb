{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd09c206-6cdc-41c6-8594-74622c56e0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# demo_moe.py\n",
    "\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score\n",
    "import numpy as np, random, math, tqdm\n",
    "\n",
    "# ---------- A. synthetic data -------------------------------------------------\n",
    "def make_data(n=100_000, d=20, n_classes=4, seed=0):\n",
    "    torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
    "    X = torch.randn(n, d)\n",
    "    missile_type = torch.randint(0, n_classes, (n, 1)).float()\n",
    "    # ground-truth logit depends on 4 features + missile_type\n",
    "    logit = (\n",
    "        1.2*X[:, 0] - 0.8*X[:, 5] + 0.6*X[:, 11] - 1.4*X[:, 17]\n",
    "        + 0.9*missile_type.squeeze()\n",
    "    )\n",
    "    y = torch.bernoulli(torch.sigmoid(logit)).unsqueeze(1)\n",
    "    X = torch.cat([X, missile_type], dim=1)  # missile_type becomes feature 21\n",
    "    return X, y\n",
    "\n",
    "# ---------- B. MH-MoE module --------------------------------------------------\n",
    "class MHMoE(nn.Module):\n",
    "    def __init__(self, in_dim, n_experts=3, hidden=80):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(in_dim, 32), nn.ReLU(), nn.Linear(32, n_experts)\n",
    "        )\n",
    "        self.experts = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(in_dim, hidden), nn.ReLU(),\n",
    "                nn.Linear(hidden, 32), nn.ReLU(),\n",
    "                nn.Linear(32, 1)\n",
    "            ) for _ in range(n_experts)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        gate_logits = self.gate(x)                 # [B, E]\n",
    "        weights = F.softmax(gate_logits, dim=1)    # mixture weights\n",
    "        expert_logits = torch.cat(\n",
    "            [e(x) for e in self.experts], dim=1)   # [B, E]\n",
    "        y_hat = (weights * expert_logits).sum(dim=1, keepdim=True)\n",
    "        return y_hat, weights\n",
    "\n",
    "# ---------- C. training loop --------------------------------------------------\n",
    "def train(model, dl, opt):\n",
    "    model.train()\n",
    "    for xb, yb in dl:\n",
    "        opt.zero_grad()\n",
    "        logits, _ = model(xb)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, yb)\n",
    "        loss.backward(); opt.step()\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_metrics(model, dl, temp=1.0):\n",
    "    model.eval(); ys, ps = [], []\n",
    "    for xb, yb in dl:\n",
    "        logits, _ = model(xb)\n",
    "        ys.append(yb); ps.append(torch.sigmoid(logits / temp))\n",
    "    y = torch.cat(ys).cpu().numpy().ravel()\n",
    "    p = torch.cat(ps).cpu().numpy().ravel()\n",
    "    acc = ( (p > .5) == y ).mean()\n",
    "    brier = brier_score_loss(y, p)\n",
    "    auc = roc_auc_score(y, p)\n",
    "    return acc, brier, auc\n",
    "\n",
    "def fit_temperature(model, dl):\n",
    "    logit_list, y_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dl:\n",
    "            logits, _ = model(xb)\n",
    "            logit_list.append(logits); y_list.append(yb)\n",
    "    logits = torch.cat(logit_list); y = torch.cat(y_list)\n",
    "    T = torch.ones(1, requires_grad=True)\n",
    "    opt = torch.optim.LBFGS([T], lr=0.1, max_iter=50)\n",
    "\n",
    "    def closure():\n",
    "        opt.zero_grad()\n",
    "        loss = F.binary_cross_entropy_with_logits(logits / T, y)\n",
    "        loss.backward(); return loss\n",
    "    opt.step(closure)\n",
    "    return T.detach().item()\n",
    "\n",
    "# ---------- D. counterfactual search -----------------------------------------\n",
    "def counterfactual(model, x, mask, lam=0.1, steps=40, lr=0.1):\n",
    "    x_cf = x.clone().detach().requires_grad_(True)\n",
    "    opt = torch.optim.Adam([x_cf], lr=lr)\n",
    "    for _ in range(steps):\n",
    "        opt.zero_grad()\n",
    "        logit, _ = model(x_cf)\n",
    "        loss = F.binary_cross_entropy_with_logits(logit, torch.ones_like(logit))\n",
    "        loss += lam * ((x_cf - x) * mask).abs().sum()\n",
    "        loss.backward(); opt.step()\n",
    "        x_cf.data = torch.clamp(x_cf.data, -4, 4)  # simple box\n",
    "    return x_cf.detach()\n",
    "\n",
    "# ---------- E. main -----------------------------------------------------------\n",
    "def main():\n",
    "    X, y = make_data()\n",
    "    ds = TensorDataset(X, y)\n",
    "    n_train = int(0.85 * len(ds))\n",
    "    n_val = len(ds) - n_train\n",
    "    train_ds, val_ds = random_split(ds, [n_train, n_val])\n",
    "    train_dl = DataLoader(train_ds, batch_size=2048, shuffle=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=4096)\n",
    "\n",
    "    model = MHMoE(in_dim=X.shape[1])\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for epoch in tqdm.trange(15):\n",
    "        train(model, train_dl, opt)\n",
    "\n",
    "    acc, brier, auc = eval_metrics(model, val_dl)\n",
    "    print(f\"raw  : acc={acc:.3f}  Brier={brier:.3f}  AUC={auc:.3f}\")\n",
    "\n",
    "    T = fit_temperature(model, DataLoader(train_ds, batch_size=4096))\n",
    "    acc, brier, auc = eval_metrics(model, val_dl, temp=T)\n",
    "    print(f\"calib: acc={acc:.3f}  Brier={brier:.3f}  AUC={auc:.3f}  T={T:.2f}\")\n",
    "\n",
    "    # counterfactual demo on first validation sample that failed\n",
    "    xb, yb = val_ds[0]\n",
    "    if yb.item() == 0:\n",
    "        mask = torch.ones_lik_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f81d4-d4a6-444e-8391-3a2059658fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
